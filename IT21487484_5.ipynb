{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4v9eXXDlV4rM/BtD/x9uw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nipunidevinuwara/sequential_models/blob/main/IT21487484_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3OhpKM9EWOy",
        "outputId": "d1b3966f-67e7-4741-c99a-cafdede36dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/MLOM/data.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "metadata": {
        "id": "UpIIXaqcFy-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_text[0:1900])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFBqOrkBLs3K",
        "outputId": "81db175c-9580-4ef8-9eee-bfc9c68ccbde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "project gutenberg's alice's adventures in wonderland, by lewis carroll\n",
            "\n",
            "this ebook is for the use of anyone anywhere at no cost and with\n",
            "almost no restrictions whatsoever.  you may copy it, give it away or\n",
            "re-use it under the terms of the project gutenberg license included\n",
            "with this ebook or online at www.gutenberg.org\n",
            "\n",
            "\n",
            "title: alice's adventures in wonderland\n",
            "\n",
            "author: lewis carroll\n",
            "\n",
            "posting date: june 25, 2008 [ebook #11]\n",
            "release date: march, 1994\n",
            "[last updated: december 20, 2011]\n",
            "\n",
            "language: english\n",
            "\n",
            "\n",
            "*** start of this project gutenberg ebook alice's adventures in wonderland ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "alice's adventures in wonderland\n",
            "\n",
            "lewis carroll\n",
            "\n",
            "the millennium fulcrum edition 3.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "chapter i. down the rabbit-hole\n",
            "\n",
            "alice was beginning to get very tired of sitting by her sister on the\n",
            "bank, and of having nothing to do: once or twice she had peeped into the\n",
            "book her sister was reading, but it had no pictures or conversations in\n",
            "it, 'and what is the use of a book,' thought alice 'without pictures or\n",
            "conversations?'\n",
            "\n",
            "so she was considering in her own mind (as well as she could, for the\n",
            "hot day made her feel very sleepy and stupid), whether the pleasure\n",
            "of making a daisy-chain would be worth the trouble of getting up and\n",
            "picking the daisies, when suddenly a white rabbit with pink eyes ran\n",
            "close by her.\n",
            "\n",
            "there was nothing so very remarkable in that; nor did alice think it so\n",
            "very much out of the way to hear the rabbit say to itself, 'oh dear!\n",
            "oh dear! i shall be late!' (when she thought it over afterwards, it\n",
            "occurred to her that she ought to have wondered at this, but at the time\n",
            "it all seemed quite natural); but when the rabbit actually took a watch\n",
            "out of its waistcoat-pocket, and looked at it, and then hurried on,\n",
            "alice started to her feet, for it flashed across her mind that she had\n",
            "never before seen a rabbit with either a waistcoat-pocket, or a watch\n",
            "to take out of it, and b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "print(chars)\n",
        "char_to_int = dict((c,i) for i,c in enumerate(chars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT5esT91GXBa",
        "outputId": "95e26a30-8dcc-444a-e2e3-2383382e9bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ww_LuzcMWQV",
        "outputId": "039f5ec5-21bb-4510-deda-d878f3bc4213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total characters : \", n_chars)\n",
        "print(\"Total Vocab(Unique characters) : \", n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh6bQ-mIG_QD",
        "outputId": "279b415d-ad13-43a9-8a4f-43fe09daa98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total characters :  163780\n",
            "Total Vocab(Unique characters) :  58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 15 #this can be changed\n",
        "#if we use 'set=10' then the next 15 characters will be selected after skipping 10 characters\n",
        "dataX = []\n",
        "dataY = [] #what we are trying to predict\n",
        "for i in range(0, n_chars-seq_length,1):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "n_patterns= len(dataY)\n",
        "print(\"Total patterns : \", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ8gC3k6IIeD",
        "outputId": "13f35b40-7086-4559-c3e0-71ba0cb23f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total patterns :  163765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy"
      ],
      "metadata": {
        "id": "HuGwTon7LSo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = numpy.reshape(dataX, (n_patterns, seq_length,1))\n",
        "#rescale values from 0 to 1\n",
        "X = X /float(n_vocab)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSMGMIGlJmHF",
        "outputId": "47cc4258-8315-4f5f-e0d3-4b1c6527f4e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.81034483]\n",
            "  [0.84482759]\n",
            "  [0.79310345]\n",
            "  ...\n",
            "  [0.77586207]\n",
            "  [0.56896552]\n",
            "  [0.62068966]]\n",
            "\n",
            " [[0.84482759]\n",
            "  [0.79310345]\n",
            "  [0.70689655]\n",
            "  ...\n",
            "  [0.56896552]\n",
            "  [0.62068966]\n",
            "  [0.84482759]]\n",
            "\n",
            " [[0.79310345]\n",
            "  [0.70689655]\n",
            "  [0.62068966]\n",
            "  ...\n",
            "  [0.62068966]\n",
            "  [0.84482759]\n",
            "  [0.65517241]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.55172414]\n",
            "  [0.56896552]\n",
            "  [0.79310345]\n",
            "  ...\n",
            "  [0.79310345]\n",
            "  [0.79310345]\n",
            "  [0.72413793]]\n",
            "\n",
            " [[0.56896552]\n",
            "  [0.79310345]\n",
            "  [0.89655172]\n",
            "  ...\n",
            "  [0.79310345]\n",
            "  [0.72413793]\n",
            "  [0.86206897]]\n",
            "\n",
            " [[0.79310345]\n",
            "  [0.89655172]\n",
            "  [0.87931034]\n",
            "  ...\n",
            "  [0.72413793]\n",
            "  [0.86206897]\n",
            "  [0.22413793]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "qKBhH5_QM-v6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "95ee0769-f345-4cef-90e7-913fb9a2878f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fdcf03730f17>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'np_utils' from 'keras.utils' (/usr/local/lib/python3.10/dist-packages/keras/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = keras.utils.to_categorical(dataY)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0rT8iFMMFcs",
        "outputId": "10eabe64-28ac-42b5-d8b6-3555f3d0eff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.layers.attention.multi_head_attention import activation\n",
        "from keras.api._v2.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "Jl_KD32FUt3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256,input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2)) #to get rid of overfitting, randomly 20% neurons will be reduced\n",
        "model.add(Dense(y.shape[1],activation='softmax'))#usually used in text generation purposes, will provide probabilities for each characters\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')#categorical crossentropy since we have multiple classes\n",
        "\n",
        "#saving weights while training\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint=ModelCheckpoint(filepath,monitor='loss',verbose=1,save_best_only=True,mode='min')\n",
        "callbacks_list=[checkpoint]\n",
        "\n"
      ],
      "metadata": {
        "id": "qb7rDaCKNMaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "model.fit(X, y , epochs=epochs, batch_size=batch_size,callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBeR6uAtQ0gc",
        "outputId": "539d28ec-78a5-46a9-e4a3-0656fbf565c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1280/1280 [==============================] - ETA: 0s - loss: 2.9862\n",
            "Epoch 1: loss improved from inf to 2.98625, saving model to weights-improvement-01-2.9862.hdf5\n",
            "1280/1280 [==============================] - 153s 117ms/step - loss: 2.9862\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1280/1280 [==============================] - ETA: 0s - loss: 2.7968\n",
            "Epoch 2: loss improved from 2.98625 to 2.79682, saving model to weights-improvement-02-2.7968.hdf5\n",
            "1280/1280 [==============================] - 151s 118ms/step - loss: 2.7968\n",
            "Epoch 3/10\n",
            "1280/1280 [==============================] - ETA: 0s - loss: 2.7185\n",
            "Epoch 3: loss improved from 2.79682 to 2.71847, saving model to weights-improvement-03-2.7185.hdf5\n",
            "1280/1280 [==============================] - 148s 116ms/step - loss: 2.7185\n",
            "Epoch 4/10\n",
            "1280/1280 [==============================] - ETA: 0s - loss: 2.6657\n",
            "Epoch 4: loss improved from 2.71847 to 2.66570, saving model to weights-improvement-04-2.6657.hdf5\n",
            "1280/1280 [==============================] - 149s 116ms/step - loss: 2.6657\n",
            "Epoch 5/10\n",
            "1280/1280 [==============================] - ETA: 0s - loss: 2.6197\n",
            "Epoch 5: loss improved from 2.66570 to 2.61969, saving model to weights-improvement-05-2.6197.hdf5\n",
            "1280/1280 [==============================] - 148s 116ms/step - loss: 2.6197\n",
            "Epoch 6/10\n",
            "1280/1280 [==============================] - ETA: 0s - loss: 2.5743\n",
            "Epoch 6: loss improved from 2.61969 to 2.57430, saving model to weights-improvement-06-2.5743.hdf5\n",
            "1280/1280 [==============================] - 148s 115ms/step - loss: 2.5743\n",
            "Epoch 7/10\n",
            "1280/1280 [==============================] - ETA: 0s - loss: 2.5295\n",
            "Epoch 7: loss improved from 2.57430 to 2.52952, saving model to weights-improvement-07-2.5295.hdf5\n",
            "1280/1280 [==============================] - 147s 115ms/step - loss: 2.5295\n",
            "Epoch 8/10\n",
            "1280/1280 [==============================] - ETA: 0s - loss: 2.4833\n",
            "Epoch 8: loss improved from 2.52952 to 2.48331, saving model to weights-improvement-08-2.4833.hdf5\n",
            "1280/1280 [==============================] - 148s 115ms/step - loss: 2.4833\n",
            "Epoch 9/10\n",
            "1280/1280 [==============================] - ETA: 0s - loss: 2.4413\n",
            "Epoch 9: loss improved from 2.48331 to 2.44132, saving model to weights-improvement-09-2.4413.hdf5\n",
            "1280/1280 [==============================] - 148s 115ms/step - loss: 2.4413\n",
            "Epoch 10/10\n",
            "1280/1280 [==============================] - ETA: 0s - loss: 2.4013\n",
            "Epoch 10: loss improved from 2.44132 to 2.40125, saving model to weights-improvement-10-2.4013.hdf5\n",
            "1280/1280 [==============================] - 146s 114ms/step - loss: 2.4013\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ca14b710820>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename =\"weights-improvement-10-2.3958.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "fciv5aIWRIrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_to_char = {i: char for i, char in enumerate(chars)}"
      ],
      "metadata": {
        "id": "D42QEn4qdXMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataX))\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "print(start)\n",
        "pattern=dataX[start]\n",
        "print(\"Seed : \")\n",
        "print(\"\\\"\",''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IV8PNbyRaK7",
        "outputId": "5287e0b8-3168-414a-ea14-b2989c2f16ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163765\n",
            "69096\n",
            "Seed : \n",
            "\" on't much care  \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = 10\n",
        "final=[]\n",
        "for i in range(length):\n",
        "  x=numpy.reshape(pattern,(1,len(pattern),1))\n",
        "  #print(x)\n",
        "  x = x / float(n_vocab)\n",
        "  #print(x)\n",
        "  prediction=model.predict(x,verbose=0)\n",
        "  index=numpy.argmax(prediction)\n",
        "\n",
        "  result=int_to_char[index]\n",
        "  #print(result)\n",
        "\n",
        "  final.append(result)\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:len(pattern)]\n",
        "print(final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N85dAmbFS5pF",
        "outputId": "90229256-580c-4915-bf35-18231b2685a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['t', 'o', ' ', 't', 'h', 'e', ' ', 'c', 'a', 'r']\n"
          ]
        }
      ]
    }
  ]
}